{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### Installing tools necessary for effdet to work\n\n!pip install antlr4-python3-runtime==4.9.3\n!pip install pycocotools==2.0.2\n!pip install /kaggle/input/effdet-030-package-dataset/packages/huggingface_hub-0.13.3-py3-none-any.whl\nimport sys\nsys.path.insert(0, \"../input/effdet-030-package-dataset/packages/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-06T23:55:58.30467Z","iopub.execute_input":"2023-04-06T23:55:58.305135Z","iopub.status.idle":"2023-04-06T23:56:47.235462Z","shell.execute_reply.started":"2023-04-06T23:55:58.305075Z","shell.execute_reply":"2023-04-06T23:56:47.234246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Installing tools to load dicom data (some data is compressed by jpeg)\n\n!cp /kaggle/input/pydicom-conda-helper/*.bz2 /kaggle/working/\n!conda install --offline 'libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -y\n!conda install --offline 'libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -y\n!conda install --offline 'gdcm-2.8.9-py37h500ead1_1.tar.bz2' -y\n!conda install --offline 'conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install --offline 'certifi-2020.12.5-py37h89c1867_1.tar.bz2' -y\n!conda install --offline 'openssl-1.1.1k-h7f98852_0.tar.bz2' -y","metadata":{"execution":{"iopub.status.busy":"2023-04-06T23:56:47.237633Z","iopub.execute_input":"2023-04-06T23:56:47.237995Z","iopub.status.idle":"2023-04-06T23:58:04.127856Z","shell.execute_reply.started":"2023-04-06T23:56:47.23796Z","shell.execute_reply":"2023-04-06T23:58:04.126295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Import libraries\n\nimport os\nimport ast\n\n# Basic libraries\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\n# Draw a sample\nimport matplotlib.pyplot as pp\nimport matplotlib.patches as patches\n%matplotlib inline\n\n# For loading image data\nfrom PIL import Image, ImageDraw\nimport pydicom\nimport cv2\n\n# Model and training\nimport torch\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader, default_collate\nimport torch.nn.functional as F\nfrom torchvision.transforms.functional import to_pil_image\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom effdet import EfficientDet, DetBenchTrain, get_efficientdet_config, DetBenchPredict","metadata":{"execution":{"iopub.status.busy":"2023-04-06T23:58:04.132532Z","iopub.execute_input":"2023-04-06T23:58:04.132962Z","iopub.status.idle":"2023-04-06T23:58:11.42188Z","shell.execute_reply.started":"2023-04-06T23:58:04.132922Z","shell.execute_reply":"2023-04-06T23:58:11.420329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Make database for training images using train_image_level.csv\n\ntrain_image_list = pd.read_csv('/kaggle/input/siim-covid19-detection/train_image_level.csv')\ntrain_image_list = train_image_list.drop(columns=['label'])\ntrain_image_list = train_image_list.rename(columns={'id':'imageID', 'StudyInstanceUID':'studyID'})\ntrain_image_list = train_image_list.assign(seriesID=pd.Series(dtype=str))\ntrain_image_list = train_image_list.reindex(columns=['studyID', 'seriesID', 'imageID', 'boxes'])\n\ntrain_root_path = '/kaggle/input/siim-covid19-detection/train'\nfor i in tqdm(range(len(train_image_list))):\n    top_dir = os.path.join(train_root_path, train_image_list.loc[i].studyID)\n    file_name = train_image_list.loc[i].imageID.split('_')[0] + '.dcm'\n    middle_dir = ''\n    for d in os.listdir(top_dir):\n        file_path = os.path.join(top_dir, d, file_name)\n        if os.path.isfile(file_path):\n            middle_dir = d\n            break\n    train_image_list.loc[i].imageID = file_name\n    train_image_list.loc[i].seriesID = middle_dir\n\ntrain_image_list = train_image_list.dropna(subset=['boxes']).reset_index()","metadata":{"execution":{"iopub.status.busy":"2023-04-06T23:58:11.425777Z","iopub.execute_input":"2023-04-06T23:58:11.426262Z","iopub.status.idle":"2023-04-06T23:58:47.587046Z","shell.execute_reply.started":"2023-04-06T23:58:11.426204Z","shell.execute_reply":"2023-04-06T23:58:47.585474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Make database for classes of training images using train_study_level.csv\n\ntrain_class_db = pd.read_csv('/kaggle/input/siim-covid19-detection/train_study_level.csv')\ntrain_class_db = train_class_db.rename(columns={\n    'id':'studyID',\n    'Negative for Pneumonia':'negative',\n    'Typical Appearance':'typical',\n    'Indeterminate Appearance':'indeterminate',\n    'Atypical Appearance':'atypical'})\n\n# Assign labels:\n#   negative: -1\n#   typical: 1\n#   indeterminate: 2\n#   atypical: 3\ntrain_image_list = train_image_list.assign(classID=pd.Series(dtype=int))\nfor i in range(len(train_image_list)):\n    studyID = train_image_list.loc[i]['studyID'] + '_study'\n    idx_loc = train_class_db[train_class_db['studyID']==studyID].index.item()\n    if train_class_db.loc[idx_loc].negative == 1:\n        train_image_list.loc[i,'classID'] = int(-1)\n    elif train_class_db.loc[idx_loc].typical == 1:\n        train_image_list.loc[i,'classID'] = int(1)\n    elif train_class_db.loc[idx_loc].indeterminate == 1:\n        train_image_list.loc[i,'classID'] = int(2)\n    elif train_class_db.loc[idx_loc].atypical == 1:\n        train_image_list.loc[i,'classID'] = int(3)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T23:58:47.589164Z","iopub.execute_input":"2023-04-06T23:58:47.59008Z","iopub.status.idle":"2023-04-06T23:58:47.61799Z","shell.execute_reply.started":"2023-04-06T23:58:47.59002Z","shell.execute_reply":"2023-04-06T23:58:47.615802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Dataset definition\n\nclass CTDataset(Dataset):\n    def __init__(self, train_root_path, train_image_list, image_size=512):\n        self.train_image_path = train_root_path\n        self.train_image_list = train_image_list\n        self.image_size = image_size\n        # in case data has no bounding boxes\n        self.albu_no_label = A.Compose([\n            A.Resize(width=self.image_size, height=self.image_size, p=1),\n            ToTensorV2()\n        ])\n        # normal process for data\n        self.albu = A.Compose([\n            A.Resize(width=self.image_size, height=self.image_size, p=1),\n            ToTensorV2()\n        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n    \n    def __len__(self):\n        return len(self.train_image_list)\n    \n    def __getitem__(self, idx):\n        # Image\n        loc = self.train_image_list.loc[idx]\n        top_path = loc.studyID\n        middle_path = loc.seriesID\n        file_name = loc.imageID\n        \n        dcm_path = os.path.join(self.train_image_path, top_path, middle_path, file_name)\n        dcm = pydicom.dcmread(dcm_path)\n        image = dcm.pixel_array.astype(\"float32\")\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        # bounding boxes & classes\n        boxes_str = train_image_list.loc[idx].boxes\n        class_id = train_image_list.loc[idx].classID\n        \n        bboxes, labels = self._get_bounding_boxes(boxes_str, class_id)\n        \n        if bboxes.shape[0] == 0:\n            result = self.albu_no_label(image=image)\n            x = result['image']\n            bboxes = torch.zeros([1, 4], dtype=torch.float32)\n            labels = torch.FloatTensor(np.array([0]))\n        else:\n            result = self.albu(\n                image = np.array(image),\n                bboxes = bboxes,\n                labels = labels\n            )\n            x = result['image']\n            box = np.array(result['bboxes'])[:,[1,0,3,2]] # from xyxy to yxyx\n            bboxes = torch.FloatTensor(box)\n            labels = torch.FloatTensor(np.array(result['labels']))\n\n        y = {\n            'bbox': bboxes,\n            'cls': labels\n        }\n        \n        return x, y\n    \n    \n    def _get_bounding_boxes(self, boxes_str, class_id):\n        boxes = []\n        labels = []\n        \n        if isinstance(boxes_str, str) == False:\n            return np.array(boxes), np.array(labels)\n        \n        bounding_boxes = ast.literal_eval(boxes_str)\n        \n        for bounding_box in bounding_boxes:\n            x0 = max(0, int(round(bounding_box['x'])))\n            y0 = max(0, int(round(bounding_box['y'])))\n            x1 = max(0, x0 + int(round(bounding_box['width'])))\n            y1 = max(0, y0 + int(round(bounding_box['height'])))\n            box = [x0, y0, x1, y1]\n            boxes.append(box)\n            labels.append(np.array([class_id]).astype(int))\n\n        boxes = np.array(boxes)\n        labels = np.array(labels)\n\n        return boxes, labels","metadata":{"execution":{"iopub.status.busy":"2023-04-06T23:58:55.232566Z","iopub.execute_input":"2023-04-06T23:58:55.233714Z","iopub.status.idle":"2023-04-06T23:58:55.253192Z","shell.execute_reply.started":"2023-04-06T23:58:55.233657Z","shell.execute_reply":"2023-04-06T23:58:55.251951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Padding processes\n\ndef pad_collate_fn(batch):\n    shapes = [item[1]['bbox'].shape[0] for item in batch]\n    max_shape = max(shapes)\n    \n    padded_batch = []\n    for x, y in batch:\n        if any(elem == 0 for elem in y['cls']):\n            continue\n        pad_size = max_shape - y['bbox'].shape[0]\n        bbox_padding = [0, 0, 0, pad_size]\n        cls_padding = [0, 0, 0, pad_size]\n        padded_y = {\n            'bbox': F.pad(y['bbox'], bbox_padding, mode='constant', value=0),\n            'cls': F.pad(y['cls'].reshape((y['cls'].shape[0],1)), cls_padding, mode='constant', value=0)\n        }\n        padded_batch.append((x, padded_y))\n    \n    return default_collate(padded_batch)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T23:58:55.254726Z","iopub.execute_input":"2023-04-06T23:58:55.255067Z","iopub.status.idle":"2023-04-06T23:58:55.26904Z","shell.execute_reply.started":"2023-04-06T23:58:55.255034Z","shell.execute_reply":"2023-04-06T23:58:55.267606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Training\n\n# you can change batch_size and num_workers here\ndataset = CTDataset(train_root_path, train_image_list)\nloader = DataLoader(\n    dataset, batch_size=4, num_workers=2, collate_fn=pad_collate_fn\n)\n\n# you can change the number of epochs here\nn_epochs = 1\n\n# you can choose which effdet model you use here\ncfg = get_efficientdet_config(f'tf_efficientdet_d0')\n# you can choose the number of classes here\ncfg.num_classes = 3\nmodel = EfficientDet(cfg)\nbench = DetBenchTrain(model)\n\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=True)\n\nprint('Starting training')\nfor epoch in range(1, n_epochs+1):\n    header = f'[{epoch}/{n_epochs}]'\n    \n    lr = optimizer.param_groups[0]['lr']\n    print(f'{header}Starting lr={lr:7f}')\n    \n    metrics = {\n        'loss': []\n    }\n    t = tqdm(loader, leave=False)\n    \n    for inputs, targets in t:\n        optimizer.zero_grad()\n        losses = bench(inputs, targets)\n        loss = losses['loss']\n        loss.backward()\n        optimizer.step()\n        iter_metrics = {\n            'loss': float(loss.item())\n        }\n        message = ' '.join([f'{k}:{v:4f}' for k, v in iter_metrics.items()])\n        t.set_description(f'{header}{message}')\n        t.refresh()\n        for k, v in iter_metrics.items():\n            metrics[k].append(v)\n        train_metrics = {k:np.mean(v) for k, v in metrics.items()}\n        train_message = ' '.join([f'{k}:{v:4f}' for k, v in train_metrics.items()])\n        print(f'{header}Train: {train_message}')\n        \n    if epoch % 10 == 0:\n        state = {\n            'epoch': epoch,\n            'state_dict': model.state_dict()\n        }\n        checkpoint_dir = f'weights/b0'\n        os.makedirs(checkpoint_dir, exist_ok=True)\n        \n        checkpoint_path = os.path.join(checkpoint_dir, f'{epoch}.pth')\n        torch.save(state, checkpoint_path)\n        print(f'{header}Saved \"{checkpoint_path}\"')\n    \n    scheduler.step(train_metrics['loss'])\n    print()\n\n\nstate = {\n    'epoch': epoch,\n    'state_dict': model.state_dict()\n}\ncheckpoint_dir = f'weights/b0'\nos.makedirs(checkpoint_dir, exist_ok=True)\n\ncheckpoint_path = os.path.join(checkpoint_dir, f'end_{epoch}.pth')\ntorch.save(state, checkpoint_path)\nprint(f'{header}Saved \"{checkpoint_path}\"')","metadata":{"execution":{"iopub.status.busy":"2023-04-06T23:59:10.193963Z","iopub.execute_input":"2023-04-06T23:59:10.195055Z","iopub.status.idle":"2023-04-07T01:02:37.569429Z","shell.execute_reply.started":"2023-04-06T23:59:10.194997Z","shell.execute_reply":"2023-04-07T01:02:37.567568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Draw the prediction for data#0\n\nnum = 0\nimage, targets = dataset.__getitem__(num)\nimage = image.unsqueeze(0)\n\nbench = DetBenchPredict(model)\nwith torch.no_grad():\n    output = bench(image)\n\nfig, ax = pp.subplots()\nax.imshow(image[0,0,:,:])\n\nfor i in range(output.shape[1]):\n    if output[0,i,4]>0.35:\n        x1 = int(output[0, i, 0])\n        y1 = int(output[0, i, 1])\n        width = int(output[0, i, 2] - output[0, i, 0])\n        height = int(output[0, i, 3] - output[0, i, 1])\n        rect = patches.Rectangle((x1, y1), width, height, edgecolor='r', facecolor='none')\n        ax.add_patch(rect)\n    \npp.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-07T01:12:14.02148Z","iopub.execute_input":"2023-04-07T01:12:14.021927Z","iopub.status.idle":"2023-04-07T01:12:14.916783Z","shell.execute_reply.started":"2023-04-07T01:12:14.02189Z","shell.execute_reply":"2023-04-07T01:12:14.915614Z"},"trusted":true},"execution_count":null,"outputs":[]}]}