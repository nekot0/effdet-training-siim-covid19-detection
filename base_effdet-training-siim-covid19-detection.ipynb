{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Sample training code for SIIM-Covid19 detection. \n","On 16 April 2023, the code worked on Kaggle platform with data sources below:\n","- https://www.kaggle.com/competitions/siim-covid19-detection\n","- https://www.kaggle.com/datasets/nekot0/effdet-030-package-dataset\n","- https://www.kaggle.com/code/awsaf49/pydicom-conda-helper"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-06T23:55:58.305135Z","iopub.status.busy":"2023-04-06T23:55:58.30467Z","iopub.status.idle":"2023-04-06T23:56:47.235462Z","shell.execute_reply":"2023-04-06T23:56:47.234246Z","shell.execute_reply.started":"2023-04-06T23:55:58.305075Z"},"trusted":true},"outputs":[],"source":["### Installing tools necessary for effdet to work\n","\n","!pip install antlr4-python3-runtime==4.9.3\n","!pip install pycocotools==2.0.2\n","!pip install /kaggle/input/effdet-030-package-dataset/packages/huggingface_hub-0.13.3-py3-none-any.whl\n","import sys\n","sys.path.insert(0, \"../input/effdet-030-package-dataset/packages/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-06T23:56:47.237995Z","iopub.status.busy":"2023-04-06T23:56:47.237633Z","iopub.status.idle":"2023-04-06T23:58:04.127856Z","shell.execute_reply":"2023-04-06T23:58:04.126295Z","shell.execute_reply.started":"2023-04-06T23:56:47.23796Z"},"trusted":true},"outputs":[],"source":["### Installing tools to load dicom data (some data is compressed by jpeg)\n","\n","!cp /kaggle/input/pydicom-conda-helper/*.bz2 /kaggle/working/\n","!conda install --offline 'libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -y\n","!conda install --offline 'libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -y\n","!conda install --offline 'gdcm-2.8.9-py37h500ead1_1.tar.bz2' -y\n","!conda install --offline 'conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n","!conda install --offline 'certifi-2020.12.5-py37h89c1867_1.tar.bz2' -y\n","!conda install --offline 'openssl-1.1.1k-h7f98852_0.tar.bz2' -y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-06T23:58:04.132962Z","iopub.status.busy":"2023-04-06T23:58:04.132532Z","iopub.status.idle":"2023-04-06T23:58:11.42188Z","shell.execute_reply":"2023-04-06T23:58:11.420329Z","shell.execute_reply.started":"2023-04-06T23:58:04.132922Z"},"trusted":true},"outputs":[],"source":["### Import libraries\n","\n","import os\n","import ast\n","\n","# Basic libraries\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","\n","# Draw a sample\n","import matplotlib.pyplot as pp\n","import matplotlib.patches as patches\n","%matplotlib inline\n","\n","# For loading image data\n","from PIL import Image, ImageDraw\n","import pydicom\n","import cv2\n","\n","# Model and training\n","import torch\n","from torch import optim\n","from torch.utils.data import Dataset, DataLoader, default_collate\n","import torch.nn.functional as F\n","from torchvision.transforms.functional import to_pil_image\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","from effdet import EfficientDet, DetBenchTrain, get_efficientdet_config, DetBenchPredict"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-06T23:58:11.426262Z","iopub.status.busy":"2023-04-06T23:58:11.425777Z","iopub.status.idle":"2023-04-06T23:58:47.587046Z","shell.execute_reply":"2023-04-06T23:58:47.585474Z","shell.execute_reply.started":"2023-04-06T23:58:11.426204Z"},"trusted":true},"outputs":[],"source":["### Make database for training images using train_image_level.csv\n","\n","train_image_list = pd.read_csv('/kaggle/input/siim-covid19-detection/train_image_level.csv')\n","train_image_list = train_image_list.drop(columns=['label'])\n","train_image_list = train_image_list.rename(columns={'id':'imageID', 'StudyInstanceUID':'studyID'})\n","train_image_list = train_image_list.assign(seriesID=pd.Series(dtype=str))\n","train_image_list = train_image_list.reindex(columns=['studyID', 'seriesID', 'imageID', 'boxes'])\n","\n","train_root_path = '/kaggle/input/siim-covid19-detection/train'\n","for i in tqdm(range(len(train_image_list))):\n","    top_dir = os.path.join(train_root_path, train_image_list.loc[i].studyID)\n","    file_name = train_image_list.loc[i].imageID.split('_')[0] + '.dcm'\n","    middle_dir = ''\n","    for d in os.listdir(top_dir):\n","        file_path = os.path.join(top_dir, d, file_name)\n","        if os.path.isfile(file_path):\n","            middle_dir = d\n","            break\n","    train_image_list.loc[i].imageID = file_name\n","    train_image_list.loc[i].seriesID = middle_dir\n","\n","train_image_list = train_image_list.dropna(subset=['boxes']).reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-06T23:58:47.59008Z","iopub.status.busy":"2023-04-06T23:58:47.589164Z","iopub.status.idle":"2023-04-06T23:58:47.61799Z","shell.execute_reply":"2023-04-06T23:58:47.615802Z","shell.execute_reply.started":"2023-04-06T23:58:47.59002Z"},"trusted":true},"outputs":[],"source":["### Make database for classes of training images using train_study_level.csv\n","\n","train_class_db = pd.read_csv('/kaggle/input/siim-covid19-detection/train_study_level.csv')\n","train_class_db = train_class_db.rename(columns={\n","    'id':'studyID',\n","    'Negative for Pneumonia':'negative',\n","    'Typical Appearance':'typical',\n","    'Indeterminate Appearance':'indeterminate',\n","    'Atypical Appearance':'atypical'})\n","\n","# Assign labels:\n","#   negative: -1\n","#   typical: 1\n","#   indeterminate: 2\n","#   atypical: 3\n","train_image_list = train_image_list.assign(classID=pd.Series(dtype=int))\n","for i in range(len(train_image_list)):\n","    studyID = train_image_list.loc[i]['studyID'] + '_study'\n","    idx_loc = train_class_db[train_class_db['studyID']==studyID].index.item()\n","    if train_class_db.loc[idx_loc].negative == 1:\n","        train_image_list.loc[i,'classID'] = int(-1)\n","    elif train_class_db.loc[idx_loc].typical == 1:\n","        train_image_list.loc[i,'classID'] = int(1)\n","    elif train_class_db.loc[idx_loc].indeterminate == 1:\n","        train_image_list.loc[i,'classID'] = int(2)\n","    elif train_class_db.loc[idx_loc].atypical == 1:\n","        train_image_list.loc[i,'classID'] = int(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-06T23:58:55.233714Z","iopub.status.busy":"2023-04-06T23:58:55.232566Z","iopub.status.idle":"2023-04-06T23:58:55.253192Z","shell.execute_reply":"2023-04-06T23:58:55.251951Z","shell.execute_reply.started":"2023-04-06T23:58:55.233657Z"},"trusted":true},"outputs":[],"source":["### Dataset definition\n","\n","class CTDataset(Dataset):\n","    def __init__(self, train_root_path, train_image_list, image_size=512):\n","        self.train_image_path = train_root_path\n","        self.train_image_list = train_image_list\n","        self.image_size = image_size\n","        # in case data has no bounding boxes\n","        self.albu_no_label = A.Compose([\n","            A.Resize(width=self.image_size, height=self.image_size, p=1),\n","            ToTensorV2()\n","        ])\n","        # normal process for data\n","        self.albu = A.Compose([\n","            A.Resize(width=self.image_size, height=self.image_size, p=1),\n","            ToTensorV2()\n","        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n","    \n","    def __len__(self):\n","        return len(self.train_image_list)\n","    \n","    def __getitem__(self, idx):\n","        # Image\n","        loc = self.train_image_list.loc[idx]\n","        top_path = loc.studyID\n","        middle_path = loc.seriesID\n","        file_name = loc.imageID\n","        \n","        dcm_path = os.path.join(self.train_image_path, top_path, middle_path, file_name)\n","        dcm = pydicom.dcmread(dcm_path)\n","        image = dcm.pixel_array.astype(\"float32\")\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        # bounding boxes & classes\n","        boxes_str = train_image_list.loc[idx].boxes\n","        class_id = train_image_list.loc[idx].classID\n","        \n","        bboxes, labels = self._get_bounding_boxes(boxes_str, class_id)\n","        \n","        if bboxes.shape[0] == 0:\n","            result = self.albu_no_label(image=image)\n","            x = result['image']\n","            bboxes = torch.zeros([1, 4], dtype=torch.float32)\n","            labels = torch.FloatTensor(np.array([0]))\n","        else:\n","            result = self.albu(\n","                image = np.array(image),\n","                bboxes = bboxes,\n","                labels = labels\n","            )\n","            x = result['image']\n","            box = np.array(result['bboxes'])[:,[1,0,3,2]] # from xyxy to yxyx\n","            bboxes = torch.FloatTensor(box)\n","            labels = torch.FloatTensor(np.array(result['labels']))\n","\n","        y = {\n","            'bbox': bboxes,\n","            'cls': labels\n","        }\n","        \n","        return x, y\n","    \n","    \n","    def _get_bounding_boxes(self, boxes_str, class_id):\n","        boxes = []\n","        labels = []\n","        \n","        if isinstance(boxes_str, str) == False:\n","            return np.array(boxes), np.array(labels)\n","        \n","        bounding_boxes = ast.literal_eval(boxes_str)\n","        \n","        for bounding_box in bounding_boxes:\n","            x0 = max(0, int(round(bounding_box['x'])))\n","            y0 = max(0, int(round(bounding_box['y'])))\n","            x1 = max(0, x0 + int(round(bounding_box['width'])))\n","            y1 = max(0, y0 + int(round(bounding_box['height'])))\n","            box = [x0, y0, x1, y1]\n","            boxes.append(box)\n","            labels.append(np.array([class_id]).astype(int))\n","\n","        boxes = np.array(boxes)\n","        labels = np.array(labels)\n","\n","        return boxes, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-06T23:58:55.255067Z","iopub.status.busy":"2023-04-06T23:58:55.254726Z","iopub.status.idle":"2023-04-06T23:58:55.26904Z","shell.execute_reply":"2023-04-06T23:58:55.267606Z","shell.execute_reply.started":"2023-04-06T23:58:55.255034Z"},"trusted":true},"outputs":[],"source":["### Padding processes\n","\n","def pad_collate_fn(batch):\n","    shapes = [item[1]['bbox'].shape[0] for item in batch]\n","    max_shape = max(shapes)\n","    \n","    padded_batch = []\n","    for x, y in batch:\n","        if any(elem == 0 for elem in y['cls']):\n","            continue\n","        pad_size = max_shape - y['bbox'].shape[0]\n","        bbox_padding = [0, 0, 0, pad_size]\n","        cls_padding = [0, 0, 0, pad_size]\n","        padded_y = {\n","            'bbox': F.pad(y['bbox'], bbox_padding, mode='constant', value=0),\n","            'cls': F.pad(y['cls'].reshape((y['cls'].shape[0],1)), cls_padding, mode='constant', value=0)\n","        }\n","        padded_batch.append((x, padded_y))\n","    \n","    return default_collate(padded_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-06T23:59:10.195055Z","iopub.status.busy":"2023-04-06T23:59:10.193963Z","iopub.status.idle":"2023-04-07T01:02:37.569429Z","shell.execute_reply":"2023-04-07T01:02:37.567568Z","shell.execute_reply.started":"2023-04-06T23:59:10.194997Z"},"trusted":true},"outputs":[],"source":["### Training\n","\n","# you can change batch_size and num_workers here\n","dataset = CTDataset(train_root_path, train_image_list)\n","loader = DataLoader(\n","    dataset, batch_size=4, num_workers=2, collate_fn=pad_collate_fn\n",")\n","\n","# you can change the number of epochs here\n","n_epochs = 1\n","\n","# you can choose which effdet model you use here\n","cfg = get_efficientdet_config(f'tf_efficientdet_d0')\n","# you can choose the number of classes here\n","cfg.num_classes = 3\n","model = EfficientDet(cfg)\n","bench = DetBenchTrain(model)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=True)\n","\n","print('Starting training')\n","for epoch in range(1, n_epochs+1):\n","    header = f'[{epoch}/{n_epochs}]'\n","    \n","    lr = optimizer.param_groups[0]['lr']\n","    print(f'{header}Starting lr={lr:7f}')\n","    \n","    metrics = {\n","        'loss': []\n","    }\n","    t = tqdm(loader, leave=False)\n","    \n","    for inputs, targets in t:\n","        optimizer.zero_grad()\n","        losses = bench(inputs, targets)\n","        loss = losses['loss']\n","        loss.backward()\n","        optimizer.step()\n","        iter_metrics = {\n","            'loss': float(loss.item())\n","        }\n","        message = ' '.join([f'{k}:{v:4f}' for k, v in iter_metrics.items()])\n","        t.set_description(f'{header}{message}')\n","        t.refresh()\n","        for k, v in iter_metrics.items():\n","            metrics[k].append(v)\n","        train_metrics = {k:np.mean(v) for k, v in metrics.items()}\n","        train_message = ' '.join([f'{k}:{v:4f}' for k, v in train_metrics.items()])\n","        print(f'{header}Train: {train_message}')\n","        \n","    if epoch % 10 == 0:\n","        state = {\n","            'epoch': epoch,\n","            'state_dict': model.state_dict()\n","        }\n","        checkpoint_dir = f'weights/b0'\n","        os.makedirs(checkpoint_dir, exist_ok=True)\n","        \n","        checkpoint_path = os.path.join(checkpoint_dir, f'{epoch}.pth')\n","        torch.save(state, checkpoint_path)\n","        print(f'{header}Saved \"{checkpoint_path}\"')\n","    \n","    scheduler.step(train_metrics['loss'])\n","    print()\n","\n","\n","state = {\n","    'epoch': epoch,\n","    'state_dict': model.state_dict()\n","}\n","checkpoint_dir = f'weights/b0'\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","\n","checkpoint_path = os.path.join(checkpoint_dir, f'end_{epoch}.pth')\n","torch.save(state, checkpoint_path)\n","print(f'{header}Saved \"{checkpoint_path}\"')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-07T01:12:14.021927Z","iopub.status.busy":"2023-04-07T01:12:14.02148Z","iopub.status.idle":"2023-04-07T01:12:14.916783Z","shell.execute_reply":"2023-04-07T01:12:14.915614Z","shell.execute_reply.started":"2023-04-07T01:12:14.02189Z"},"trusted":true},"outputs":[],"source":["### Draw the prediction for data#0\n","\n","num = 0\n","image, targets = dataset.__getitem__(num)\n","image = image.unsqueeze(0)\n","\n","bench = DetBenchPredict(model)\n","with torch.no_grad():\n","    output = bench(image)\n","\n","fig, ax = pp.subplots()\n","ax.imshow(image[0,0,:,:])\n","\n","for i in range(output.shape[1]):\n","    if output[0,i,4]>0.35:\n","        x1 = int(output[0, i, 0])\n","        y1 = int(output[0, i, 1])\n","        width = int(output[0, i, 2] - output[0, i, 0])\n","        height = int(output[0, i, 3] - output[0, i, 1])\n","        rect = patches.Rectangle((x1, y1), width, height, edgecolor='r', facecolor='none')\n","        ax.add_patch(rect)\n","    \n","pp.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
